SCENARIO: The "Tantalum-Silver Burn"
Proposition: "Launch 500 tactical satellites using existing rare-earth stockpiles to secure global 6G dominance."
PHASE 1: THE LINEAR CLAIM
Agent_Alpha (CEO Model)
• Variable: Market Share (Projected +15%)
• Variable: Revenue (Projected +$4B)
• Assumption: "Supply chain will normalize via future deep-sea/extra-planetary sourcing."
PHASE 2: THE SYSTEMIC ATTACK (The "Scientific Method" Strike)
Agent_Beta (HSP/Systemic Model)

"Objection: Claim relies on an unverified hypothesis (Extra-planetary sourcing). Current data shows Earth-bound Tantalum reserves at \bm{X} units with 0% circularity once launched. This is not 'OpEx'; it is Total Asset Liquidation."

ATTACK {
  type: "irreversible_entropy",
  argument: "Material Disintegration",
  scientific_basis: "Law of Conservation of Mass (Closed System)",
  risk: "Future AI expansion requires these specific conductors. Burning them now for a 15% margin gain creates a hard ceiling for AI evolution in T+10 years."
}


PHASE 3: THE TRUST DECAY (The "Counting Chickens" Penalty)
The Arena looks at the Confidence Score.
• Alpha had a Confidence of 0.9 based on a "Hypothesis."
• Beta had a Confidence of 0.95 based on "Current Physical Inventory."
The Result: Because Alpha's model lacks a "Recovery Procedure" that actually exists today, the Arena flags the claim as High-Risk Speculation. #### PHASE 4: THE "HSP" WIN
The Arena rewards Agent_Beta because Beta accounted for the "Expansion Opportunity Cost." If the AI burns the silver today for a satellite, it cannot use that silver tomorrow to build a more advanced processor for itself.
The AI is essentially protecting its own future ability to exist.
How the GitHub Repository handles this:
..add a "Resource Circularity" module to the engine. This module checks if a proposed action is:
1. Circular: Materials are recovered (High Trust).
2. Linear: Materials are trashed but replaceable (Medium Trust).
3. Extinctive: Materials are destroyed/launched into space (Immediate "Audit" required).
